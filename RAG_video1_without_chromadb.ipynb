{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377379e1-641d-494f-a7bc-3c6c6c84331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -qU langchain-groq\n",
    "#pip install python-dotenv\n",
    "#pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1759dc-adf3-4fee-8203-90cd40aacfc7",
   "metadata": {},
   "source": [
    "# Invoke LLM using RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e698e8b-41bb-47f7-87a7-65b4ae63e22c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1772d1-82fb-47cf-9c48-42cb0312124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# --- use online prompt---\n",
    "from langchain import hub\n",
    "\n",
    "#--- custom prompt template ----------\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c418f-6e2d-4f9b-a24d-824ea62f9323",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Environment Setup\n",
    "\n",
    "Note: Hugging Face is about model access and development, while Groq is about optimized hardware for running those models rapidly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9de83-f7ab-467f-a318-3a7e3b61a255",
   "metadata": {},
   "source": [
    "# Setup GROQ - for accessing LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec7ce3b-ee4e-4e4c-848e-4c72ef6d5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6eb6a-385a-4d48-864e-9ec3549668e3",
   "metadata": {},
   "source": [
    "# Create LLM instance from GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2872f6ed-b92b-4e01-80e6-d343703ba61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a2cd9-ca17-43d5-bb28-6f000a7ea339",
   "metadata": {},
   "source": [
    "# Setup HuggingFace -- for accessing embedding model \n",
    "\n",
    "# we can use huggingface to get the enbedding in the cloud OR we can use local embedding model to get the embedding, e.g using OLAMA\n",
    "\n",
    "N.B. https://python.langchain.com/docs/how_to/embed_text/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1400fb47-2358-4d95-971b-795e9756c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_api_key = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011e1f7-f5e6-4858-bada-90e3cad1ba47",
   "metadata": {},
   "source": [
    "# Setup the embedding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e62a2b-41f3-45e3-a3b6-29decfe7b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",    \n",
    "    encode_kwargs={\"normalize_embeddings\": True}  # Normalize embeddings for cosine similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7bc78-eff4-4bc9-928a-f83975dfed60",
   "metadata": {},
   "source": [
    "# Test embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bacaabb-b814-4d8e-9234-8006e1f6fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04714725911617279, 0.031214414164423943, 0.06171492859721184, 0.01215528417378664, 0.03618667274713516, 0.018930858001112938, -0.05314081907272339, -0.05064268410205841, 0.006911817472428083, -0.016089562326669693, 0.05560332164168358, -0.00655879732221365, -0.020847702398896217, 0.05155806988477707, 0.10991392284631729, 0.062482450157403946, -0.023179661482572556, 0.058812081813812256, 0.03772741183638573, 0.009840325452387333, -0.010646358132362366, 0.0930664911866188, 0.045571282505989075, -0.09587831050157547, 0.022258056327700615, 0.013583502732217312, -0.033910539001226425, -0.03657962754368782, 0.10744249820709229, -0.002959347330033779, -0.009816817939281464, -0.01652284525334835, -0.0014099582331255078, 0.06383546441793442, -0.04078644886612892, 0.10934137552976608, 0.02877010777592659, 0.09480557590723038, -0.08343128114938736, -0.008077527396380901, -0.110220767557621, -0.015364536084234715, 0.018267905339598656, 0.004388584289699793, 0.09433092921972275, 0.03693832457065582, -0.09880053997039795, 0.05844934284687042, -0.0024947943165898323, -0.054703377187252045, -0.0803656205534935, -0.11381879448890686, 0.029089059680700302, 0.021617788821458817, 0.011952885426580906, 0.04168418422341347, 0.0008439263328909874, -0.0861615538597107, -0.03807563707232475, -0.028660355135798454, 0.009446339681744576, -0.007058441638946533, -0.04684063047170639, 0.015380468219518661, -0.029018258675932884, -0.00701030483469367, 0.010572096332907677, 0.09392333775758743, -0.01926330476999283, 0.07198687642812729, -0.05561117082834244, 0.01195435132831335, -0.04104609787464142, 0.0741499587893486, 0.019153829663991928, 0.04271147400140762, -0.010651212185621262, -0.07728241384029388, 0.04661248251795769, -0.059099163860082626, -0.011586812324821949, 0.04115065187215805, 0.017089003697037697, 0.019327567890286446, -0.01718536950647831, -0.0341736301779747, 0.0028034609276801348, -0.05698227882385254, -0.1297617405653, 0.05961214005947113, -0.0047727287746965885, -0.034707363694906235, 0.014037448912858963, -0.06265345960855484, -0.08309408277273178, -0.0027166903018951416, -0.046920131891965866, -0.029481204226613045, -0.08527583628892899, 0.08418605476617813, -0.0019170474261045456, -0.021218478679656982, 0.014647471718490124, -0.026638025417923927, -0.05641927570104599, -0.09206036478281021, -0.05818798020482063, -0.08737052232027054, 0.04652683436870575, -0.04406331107020378, -0.004922317340970039, -0.03205031156539917, -0.06755539029836655, -0.02225407212972641, 0.0719943642616272, -0.04799048602581024, -0.005640283692628145, -0.0651719868183136, 0.11748500168323517, -0.018309172242879868, 0.004456884693354368, 0.02766418643295765, 0.016295170411467552, 0.004177628085017204, -0.01049269549548626, -0.07536112517118454, 0.026037853211164474, -1.541838634623992e-33, 0.09819350391626358, 0.10395385324954987, 0.019002094864845276, 0.007076269946992397, 0.004189670085906982, 0.023624250665307045, -0.05906401947140694, -0.032561615109443665, -0.07670880854129791, 0.014394953846931458, -0.0650637224316597, 0.021182773634791374, 0.0383380651473999, 0.004087488166987896, -0.016237298026680946, -0.0036855728831142187, -0.1368996500968933, 0.08196628838777542, -0.032207075506448746, 0.05111238360404968, -0.05245146155357361, -0.01612708903849125, 0.03236325830221176, 0.02171148732304573, -0.06817178428173065, 0.014810783788561821, 0.04701263830065727, -0.05137794837355614, 0.014312722720205784, 0.0015915335388854146, -0.02532881125807762, 0.024564776569604874, -0.020931489765644073, -0.015603204257786274, 0.07339984178543091, 0.006272190250456333, 0.0029654945246875286, -0.10964533686637878, -0.039624474942684174, -0.005573230795562267, -0.04975777491927147, 0.03975464776158333, 0.002080672886222601, -0.04093252867460251, 0.028020402416586876, 0.09213917702436447, -0.03118201158940792, -0.04498131945729256, 0.01280243694782257, -0.024302884936332703, 0.11137153208255768, 0.02024438977241516, 0.01451181247830391, 0.03440486639738083, -0.05312406271696091, 0.004695466719567776, 0.03867991268634796, 0.03265674039721489, 0.022760843858122826, 0.07719270139932632, 0.027430128306150436, -0.010399247519671917, 0.10671013593673706, -0.06876635551452637, -0.026588549837470055, 0.02009548433125019, -0.020738914608955383, 0.030737126246094704, 0.011419808492064476, -0.0032782554626464844, -0.02602267824113369, 0.036056987941265106, 0.03461090847849846, -0.030084867030382156, -0.025524428114295006, -0.016995809972286224, 0.10889314860105515, 9.184034570353106e-05, 0.04092373698949814, 0.07034948468208313, -0.00010077702609123662, -0.037609685212373734, -0.0028637307696044445, -0.08727969974279404, -0.03274573013186455, -0.15105608105659485, -0.018008384853601456, -0.07907664775848389, 0.04216073080897331, 0.048581842333078384, -0.008559361100196838, 0.052756886929273605, 0.03960845246911049, -0.009363540448248386, -0.05328042432665825, 1.0556674872708367e-33, 0.04669250175356865, -0.04929743707180023, -0.039418164640665054, -0.012269129976630211, -0.01951499655842781, 0.013721096329391003, -0.013352910056710243, 0.06627106666564941, 0.04286344349384308, -0.03794627636671066, 0.03899499773979187, -0.079677052795887, 0.03143560513854027, -0.000936936354264617, 0.09764490276575089, -0.007148207165300846, 0.054623015224933624, -0.006080116610974073, -0.025389589369297028, 0.09550534188747406, 0.02406301721930504, 0.037078607827425, -0.03165591135621071, 0.03349550813436508, 0.020027734339237213, 0.034129947423934937, -0.012297837063670158, -0.0294230654835701, -0.006077926605939865, -0.055998556315898895, 0.03994981572031975, -0.02347906492650509, -0.06720628589391708, 0.0317976213991642, -0.0536554753780365, 0.010716453194618225, 0.0024288324639201164, 0.00881996937096119, -0.030912218615412712, -0.012334770523011684, 0.10468462854623795, 0.05718257650732994, -0.04734373465180397, 0.07674478739500046, 0.0279107466340065, 0.026233823969960213, -0.1310957670211792, -0.006505118682980537, -0.09128779172897339, 0.059812307357788086, -0.027602488175034523, -0.022370560094714165, -0.04963790997862816, -0.08474386483430862, -0.04171746224164963, -0.031924303621053696, 0.07203128188848495, -0.048926886171102524, -0.07244958728551865, 0.0039781611412763596, -0.11057685315608978, -0.0016087148105725646, -0.016406690701842308, 0.027084412053227425, 0.07983233779668808, -0.02563565783202648, -0.003009746316820383, -0.038823265582323074, -0.10293953120708466, -0.04612797498703003, 0.022460753098130226, 0.032409459352493286, -0.026005376130342484, 0.05208808183670044, -0.011258060112595558, 0.03279964253306389, 0.06542132794857025, -0.054626550525426865, -0.045175667852163315, -0.05714799091219902, 0.009336580522358418, -0.0399404875934124, 0.05337734520435333, 0.022068891674280167, 0.03894216567277908, 0.07948624342679977, -0.03325992077589035, 0.06179501861333847, 0.020021403208374977, 0.02196068875491619, -0.08153402805328369, 0.03249429538846016, -0.01126362755894661, 0.07213319092988968, 0.019246507436037064, -1.505786428879219e-08, -0.09524828940629959, -0.06302470713853836, 0.004183139186352491, -0.04438713192939758, -0.04115912690758705, 0.023166224360466003, 0.023053428158164024, -0.05733821541070938, -0.027327178046107292, 0.01227562502026558, 0.08364959061145782, 0.05330704525113106, -0.028023768216371536, 0.008867921307682991, 0.004226088058203459, 0.000904739077668637, 0.018304957076907158, 0.027435971423983574, -0.04828832671046257, -0.0431048758327961, -0.021428655833005905, 0.055859196931123734, -0.027230646461248398, 0.0265548937022686, 0.054473891854286194, -0.03651950880885124, -0.08664577454328537, 0.03748698905110359, -0.0022643550764769316, -0.08314713090658188, 0.03341507911682129, 0.06250223517417908, 0.0066375103779137135, 0.004187505692243576, 0.13169611990451813, 0.07554253190755844, 0.0255026426166296, -0.0818583220243454, 0.02653691917657852, 0.03267482668161392, 0.03273743763566017, 0.09713929146528244, -0.017775269225239754, -0.0415491983294487, 0.050053153187036514, 0.05307169631123543, 0.09634049236774445, -0.09175533801317215, 0.027719466015696526, -0.0003742413246072829, 0.016289303079247475, -0.0576951801776886, 0.005997237283736467, 0.05334848165512085, 0.014418878592550755, 0.0421706959605217, -0.018113022670149803, 0.010455228388309479, 0.07206558436155319, 0.055101994425058365, 0.031016957014799118, 0.04677426069974899, 0.03744145855307579, 0.12814602255821228]\n"
     ]
    }
   ],
   "source": [
    "# Example text to encode\n",
    "text = \"Hugging Face provides great NLP tools.\"\n",
    "\n",
    "# Get the embeddings\n",
    "embedding_vector = embeddings.embed_query(text)\n",
    "\n",
    "print(embedding_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf857c-85a2-4273-a755-800518a0fb2a",
   "metadata": {},
   "source": [
    "# Read a pdf/txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5bd586-29b5-4921-adff-a1be5ba6b12f",
   "metadata": {},
   "source": [
    "# 1) Define the directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b2be46-3bef-4a1e-9c85-9fec5333de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "fulldir = Path(\"C:\\\\GenAI\\\\RAG\\\\llm_story_v1\")  # Convert string to Path object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fda09b-41aa-4d14-9f9b-87882d4a974e",
   "metadata": {},
   "source": [
    "# Use the absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78250338-023d-4a21-81c2-c3ca4b2159ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirloader = DirectoryLoader(\n",
    "    fulldir.absolute(), \n",
    "    glob='**/*.txt', \n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}  # Explicitly set encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8affcd1-9847-46c6-b532-b12e1236bb9a",
   "metadata": {},
   "source": [
    "# Instantiate the loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23511477-ed1d-4d7f-9abc-45af55d968d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated loader\n"
     ]
    }
   ],
   "source": [
    "print(\"Instantiated loader\")\n",
    "dirdata = dirloader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46cb873-944e-48ae-b9a2-e41fba1a1238",
   "metadata": {},
   "source": [
    "# Split / chunk the file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f4b981-0b60-4a35-9d28-07185c74a86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split / chunk the file content\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Split / chunk the file content\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(dirdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1c077-f847-45b3-b861-8fe37057c74d",
   "metadata": {},
   "source": [
    "# Testing ------> check the content of splits object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd7a927-8390-499a-af2a-a2499b9d336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\GenAI\\\\RAG\\\\llm_story_v1\\\\story1.txt'}, page_content='The Fox and the Grapes\\n\\nOnce upon a time, a fox was traveling through the countryside, when he spotted a beautiful bunch of ripe grapes hanging from a vine. The vine was bound along the branch of a tree, and the perfect grapes hung right above the fox’s head.\\n\\nThe fox jumped to take a bite, but couldn’t reach the branch. So he backed up to take a running leap, and again fell short. He tried over and over, then sat down.\\n\\nThen he shook his head. “What a fool I’ve been,” he thinks. “Why, just look at those grapes! They’re obviously sour. Why have I been wasting my time on a bunch of sour grapes?” And with great disdain he trotted off.\\n\\nAesop’s moral: “There are many who pretend to despise and belittle that which is beyond their reach.”\\n\\nThis is a very useful story. It surprises me how often I fall into this trap—of deciding that something’s not worth having, if I fear I can’t have it.\\n\\nIn the diary of writer Virginia Woolf, I was struck to see her reminding herself of the importance of avoiding this sour-grapes attitude. She wrote:\\n\\nYears & years ago…I said to myself, walking up the hill at Beireuth, never pretend that the things you haven’t got are not worth having.\\n\\nI find myself turning this phrase over in my head often: “Never pretend that the things you haven’t got are not worth having.”\\n\\nIt’s easy to act like the fox with his grapes, but it means denying the truth about what we really want, and that form of self-deception can be destructive.')]\n"
     ]
    }
   ],
   "source": [
    "print(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686b85a-8e61-4b91-b1b1-ed2150db7345",
   "metadata": {},
   "source": [
    "# Validate the string - should not contain any special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb507176-7018-4038-ad91-b77d22ab67c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "page_content='The Fox and the Grapes\n",
      "\n",
      "Once upon a time, a fox was traveling through the countryside, when he spotted a beautiful bunch of ripe grapes hanging from a vine. The vine was bound along the branch of a tree, and the perfect grapes hung right above the fox’s head.\n",
      "\n",
      "The fox jumped to take a bite, but couldn’t reach the branch. So he backed up to take a running leap, and again fell short. He tried over and over, then sat down.\n",
      "\n",
      "Then he shook his head. “What a fool I’ve been,” he thinks. “Why, just look at those grapes! They’re obviously sour. Why have I been wasting my time on a bunch of sour grapes?” And with great disdain he trotted off.\n",
      "\n",
      "Aesop’s moral: “There are many who pretend to despise and belittle that which is beyond their reach.”\n",
      "\n",
      "This is a very useful story. It surprises me how often I fall into this trap—of deciding that something’s not worth having, if I fear I can’t have it.\n",
      "\n",
      "In the diary of writer Virginia Woolf, I was struck to see her reminding herself of the importance of avoiding this sour-grapes attitude. She wrote:\n",
      "\n",
      "Years & years ago…I said to myself, walking up the hill at Beireuth, never pretend that the things you haven’t got are not worth having.\n",
      "\n",
      "I find myself turning this phrase over in my head often: “Never pretend that the things you haven’t got are not worth having.”\n",
      "\n",
      "It’s easy to act like the fox with his grapes, but it means denying the truth about what we really want, and that form of self-deception can be destructive.' metadata={'source': 'C:\\\\GenAI\\\\RAG\\\\llm_story_v1\\\\story1.txt'}\n"
     ]
    }
   ],
   "source": [
    "for i, split in enumerate(splits):\n",
    "    print(f\"Split {i+1}:\")\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9791369-aa81-479e-8be0-3e9cb724fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for split in splits:\n",
    "   # print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce5b65f7-038b-4e44-a82c-dc7cd1dc8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = splits # Since splits are already strings, no need for doc.page_content\n",
    "\n",
    "#print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5a49b-d810-488c-9236-573a39cfbefb",
   "metadata": {},
   "source": [
    "# Testing ------>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01781352-a54e-4636-9d8e-57783c8ca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999fb8cf-02f6-4003-b801-a999e4da6601",
   "metadata": {},
   "source": [
    "# Create the prompt - load the online prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33edc5b4-f9cd-4c06-9caf-233d7e1d4498",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d719f-da27-438c-a3fe-d19cd9b280e5",
   "metadata": {},
   "source": [
    "# ------ Create Custom Prompt --------- Another way to create Custom prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6472b813-960a-4600-953a-b9bdf0b22a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "            Question: {question} \n",
    "            Context: {context} \n",
    "            Answer:\n",
    "            '''\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e02f0e-73f7-47bf-8e62-d0f19a8313ff",
   "metadata": {},
   "source": [
    "# ------- Format the document---- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef98ace-1e44-4b27-9e9c-7a3483af6bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    \n",
    "formatted_docs = format_docs(documents) \n",
    "\n",
    "\n",
    "print(type(formatted_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a3945-3341-4671-9d86-6c953a79a452",
   "metadata": {},
   "source": [
    "# Create LangChain chain - Build the RAG Pipeline\n",
    "This involves creating a query engine that can retrieve relevant information from your embeddings and augment the LLM’s responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ffe6241-7f87-4024-b2eb-78dbf9ffe14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": RunnableLambda(lambda _: formatted_docs), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c3483-7206-435d-8c0d-fa3f2fdbdb17",
   "metadata": {},
   "source": [
    "# ------- use custom prompt - template ---------- optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4475e4c-776c-4656-9525-b619c1ce0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9446ec-bd91-4cae-b963-ee5a6e3902a8",
   "metadata": {},
   "source": [
    "# Invoke the LLM with user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c79c371f-877a-425c-bc88-9cdb665d3ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The moral of the story is that many people pretend to despise or belittle something that is beyond their reach, in order to hide their disappointment or lack of achievement. It's a form of self-deception that can be destructive.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is the moral of the story ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2994fd70-88fd-4f8c-88ab-cedf6985599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a summary of the story in three lines:\\n\\nA fox tries to reach a bunch of ripe grapes but fails, and then decides they're sour and not worth having. The fox's behavior is a metaphor for people who pretend to despise something they can't have. The story teaches us not to pretend something is not worth having just because we can't get it.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"write the summary of the story in 3 lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdbf72-8b83-4308-80ac-dd85b4bea38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5e2fc-3f73-40d8-9964-387672bbabc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
